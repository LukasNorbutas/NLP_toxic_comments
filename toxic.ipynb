{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "toxic",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehtry6nCKOf2",
        "colab_type": "text"
      },
      "source": [
        "# Toxic comments classifier\n",
        "\n",
        "**Problem**: Varying-length textual comments, containing typos, slang, rare words, etc.<br>\n",
        "**Outcome**: Multi-label classification of 6 types of \"toxicity\" of comments. Labels slightly correlated, very sparse and imbalanced.\n",
        "<br>\n",
        "<br>\n",
        "This notebook shows how to apply RNN for this classification task, using Bidirectional LSTM and hybrid lstm+conv1D architectures. Several losses are explored (BCE and focal loss). Glove pre-trained embeddings are used in some of the models.\n",
        "<br>\n",
        "<br>\n",
        "**Model eval on val data (Macro F1)**:<br>\n",
        "- M1: LSTM + fixed class weights (embedding64 + 2 bidirectional layers): **0.43**\n",
        "- M2: M1 + undersampling 0s + oversampling small cats + embedding128: **0.47**\n",
        "- M3: LSTM + focal loss (embedding256, lower dropouts + 2 bidirectional layers): **0.35**\n",
        "- M4: M1 + pre-trained Glove embeddings (200d), back to BCE loss: **0.47**\n",
        "- M5: Hybrid LSTM+Conv + Glove embeddings (200d + Conv1D*128 + 2 bidirectional: ****\n",
        "\n",
        "**TO-DOs**:<br>\n",
        "Plenty of things to improve:<br>\n",
        "- Larger pre-trained embeddings (currently used 200d only)\n",
        "- Larger variety of architectures+pre-trained embeddings ensembling\n",
        "- Did not adequately address class imbalance - class weights/sampling don't work, but different loss functions might\n",
        "- Train on the entire dataset\n",
        "- Translation augmentation \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB8ryIHaLFqE",
        "colab_type": "text"
      },
      "source": [
        "# 0. Data/library imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlxuIjC8lu4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install TF2.0 gpu, helper lib and pretrained glove embeddings\n",
        "# !pip uninstall tensorflow\n",
        "# !pip install tensorflow-gpu\n",
        "# !pip install DLHelper\n",
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH1g4sjovREC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from DLHelper.imports import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGSQtiM2h3SB",
        "colab_type": "code",
        "outputId": "c47a070b-1219-4f07-86cb-5e20961fed3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "# Download kaggle data\n",
        "keys = eval(open('kaggle.json', 'r').read())\n",
        "\n",
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = keys[\"username\"]  \n",
        "os.environ['KAGGLE_KEY'] = keys[\"key\"]\n",
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.39M [00:00<?, ?B/s]\n",
            "100% 1.39M/1.39M [00:00<00:00, 46.9MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 38% 9.00M/23.4M [00:00<00:00, 21.5MB/s]\n",
            "100% 23.4M/23.4M [00:00<00:00, 47.7MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 34% 9.00M/26.3M [00:00<00:00, 20.3MB/s]\n",
            "100% 26.3M/26.3M [00:00<00:00, 44.6MB/s]\n",
            "Downloading test_labels.csv.zip to /content\n",
            "  0% 0.00/1.46M [00:00<?, ?B/s]\n",
            "100% 1.46M/1.46M [00:00<00:00, 97.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzXQUPGhlOac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make data dir\n",
        "DATA_DIR = Path('data/toxic')\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWNTwt_Nww-R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "e4ca7216-f9f7-410c-fea9-2dbc29145cfd"
      },
      "source": [
        "# # Unzip data to data dir\n",
        "# !unzip train.csv.zip -d {DATA_DIR}/'train'\n",
        "# !unzip glove.6B.zip -d {DATA_DIR}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: data/toxic/train/train.csv  \n",
            "Archive:  glove.6B.zip\n",
            "  inflating: data/toxic/glove.6B.50d.txt  \n",
            "  inflating: data/toxic/glove.6B.100d.txt  \n",
            "  inflating: data/toxic/glove.6B.200d.txt  \n",
            "  inflating: data/toxic/glove.6B.300d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY26ZPjYw_Gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read data\n",
        "data_df = pd.read_csv(DATA_DIR/'train/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDENuqp8LU0m",
        "colab_type": "text"
      },
      "source": [
        "# 1. Exploratory data analysis\n",
        "* 6 label classes, two types of imbalance: 1) there are generally way more 0's \n",
        "than 1's, largest outcome category accounts for 10% of all examples; 2) outcome classes are imbalanced among themselves (largest/smallest categories differ >10x)<br>\n",
        "* Most examples have 0 labels (~90%). If we use pre-trained embeddings, we might be able to undersample these comments a lot. Virtually no examples with 5-6 labels.\n",
        "* The smallest class (\"threats\") correlated with all other classes, hence it will not be easy to oversample it<br>\n",
        "* Comments vary in length a lot, from 6 to 5,000 chars (most around 100-300)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef22iq4Xxb67",
        "colab_type": "code",
        "outputId": "95fe3a10-12e9-4161-b900-e32884100d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "data_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg0A1dwhxd33",
        "colab_type": "code",
        "outputId": "d25a1987-992c-47a2-9579-eac13b53f485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# Normalized label frequencies\n",
        "data_df.iloc[:, 2:].apply(np.mean, axis=0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "toxic            0.095844\n",
              "severe_toxic     0.009996\n",
              "obscene          0.052948\n",
              "threat           0.002996\n",
              "insult           0.049364\n",
              "identity_hate    0.008805\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eA8YgKI8iaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "1ec4b4f1-cd97-4e5a-cd93-1320f3a27c1e"
      },
      "source": [
        "# Comment textual length distribution\n",
        "data_df[\"comment_text\"].map(lambda x: len(x)).describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    159571.000000\n",
              "mean        394.073221\n",
              "std         590.720282\n",
              "min           6.000000\n",
              "25%          96.000000\n",
              "50%         205.000000\n",
              "75%         435.000000\n",
              "max        5000.000000\n",
              "Name: comment_text, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfNgYRqHx-Aw",
        "colab_type": "code",
        "outputId": "48c02d53-9df5-4e33-8f01-a1fabc18eef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "# Number of 1-labels per example\n",
        "data_df.iloc[:, 2:].apply(np.sum, axis=1).value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    143346\n",
              "1      6360\n",
              "3      4209\n",
              "2      3480\n",
              "4      1760\n",
              "5       385\n",
              "6        31\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkeMZvdCyNjk",
        "colab_type": "code",
        "outputId": "41846a12-36f5-4e3d-d87b-91487ba207e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# Label correlations\n",
        "heatmap_inp = data_df.iloc[(data_df.iloc[:, 2:].apply(np.sum, axis=1) > 0).index.values, 2:].corr()\n",
        "sns.heatmap(heatmap_inp, vmin=-1, vmax=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbad37d4668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAE0CAYAAAD3zO6EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxknHzMwK46RjZmaFcdIxM7PC/H9BGRlM5LH4TgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF5Mn7yE69g7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "8a5b66db-426c-45e0-fca3-c25058dad05e"
      },
      "source": [
        "# Nastiest comments\n",
        "data_df[(data_df.iloc[:, 2:].apply(np.sum, axis=1) == 6)].iloc[:5, 1]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1017     WOULDN'T BE THE FIRST TIME BITCH. FUCK YOU I'L...\n",
              "1312     SHUT UP, YOU FAT POOP, OR I WILL KICK YOUR ASS!!!\n",
              "7299     You're a stupid cunt \\n\\nFuck you dumb arse, y...\n",
              "13648    Bitch \\n\\nYou are a little bitch. I fuckin spe...\n",
              "13964    I am going to murder ZimZalaBim ST47 for being...\n",
              "Name: comment_text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tbrEI3wMYkK",
        "colab_type": "text"
      },
      "source": [
        "# 2. Train/val/test split + pipeline\n",
        "\n",
        "For time-saving reasons, 20% of train and validation data will be used in further analyses. NOTE: for over/undersampling, we will use 100% of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vIu_8Ri01Kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train test split\n",
        "data_df = data_df.sample(frac=1, replace=False)\n",
        "train_df = data_df[:np.ceil(data_df.shape[0] * 0.8).astype(np.int)]\n",
        "val_df = data_df[np.ceil(data_df.shape[0] * 0.8).astype(np.int):np.ceil(data_df.shape[0] * 0.9).astype(np.int)].reset_index(drop=True)\n",
        "test_df = data_df[np.ceil(data_df.shape[0] * 0.9).astype(np.int):].reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJClGi6_1kvO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7883e365-15df-4cd9-bccc-f584ee0285ea"
      },
      "source": [
        "print(train_df.shape, val_df.shape, test_df.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(127657, 8) (15957, 8) (15957, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX8oWPAiDtj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's work with 20% of the data\n",
        "train_df_small = train_df.sample(frac=0.2)\n",
        "val_df_small = val_df.sample(frac=0.2)\n",
        "test_df_small = test_df.sample(frac=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmsi_k1mKkrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "1dca7231-4855-4ecd-a341-ee335a749f31"
      },
      "source": [
        "train_df_small.iloc[:,2:].apply(np.mean)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "toxic            0.094865\n",
              "severe_toxic     0.010066\n",
              "obscene          0.051153\n",
              "threat           0.002624\n",
              "insult           0.048529\n",
              "identity_hate    0.009204\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJzppKdGKp5y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "45a006b2-974f-4330-ff94-d61b99a817e6"
      },
      "source": [
        "val_df_small.iloc[:,2:].describe()"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3191.000000</td>\n",
              "      <td>3191.000000</td>\n",
              "      <td>3191.000000</td>\n",
              "      <td>3191.000000</td>\n",
              "      <td>3191.000000</td>\n",
              "      <td>3191.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.106550</td>\n",
              "      <td>0.012222</td>\n",
              "      <td>0.060796</td>\n",
              "      <td>0.005014</td>\n",
              "      <td>0.057976</td>\n",
              "      <td>0.010655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.308588</td>\n",
              "      <td>0.109892</td>\n",
              "      <td>0.238993</td>\n",
              "      <td>0.070644</td>\n",
              "      <td>0.233734</td>\n",
              "      <td>0.102688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             toxic  severe_toxic  ...       insult  identity_hate\n",
              "count  3191.000000   3191.000000  ...  3191.000000    3191.000000\n",
              "mean      0.106550      0.012222  ...     0.057976       0.010655\n",
              "std       0.308588      0.109892  ...     0.233734       0.102688\n",
              "min       0.000000      0.000000  ...     0.000000       0.000000\n",
              "25%       0.000000      0.000000  ...     0.000000       0.000000\n",
              "50%       0.000000      0.000000  ...     0.000000       0.000000\n",
              "75%       0.000000      0.000000  ...     0.000000       0.000000\n",
              "max       1.000000      1.000000  ...     1.000000       1.000000\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC61uI4I2sbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataframes to datasets\n",
        "def df_to_ds(df):\n",
        "    label_df = df.iloc[:, 2:]\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(label_df.values)\n",
        "    text_df = df['comment_text']\n",
        "    text_ds = tf.data.Dataset.from_tensor_slices(text_df.values)\n",
        "    out_ds = tf.data.Dataset.zip((text_ds, label_ds))\n",
        "    return out_ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uklkWvSy4Lks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_ds, val_ds, test_ds) = (df_to_ds(train_df_small), df_to_ds(val_df_small), df_to_ds(test_df_small))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uRPzNoP7tvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "1d463ff4-b4d1-4350-e702-626f1bf30192"
      },
      "source": [
        "for x,y in train_ds.take(16):\n",
        "    print(x)\n",
        "    print(y)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b\"The list is certainly not all-inclusinve and is not intended to be that.  Since your father uses the term, it's likely that others did as well. Often these things are started in or perpetuated by novels and comic books.  At any rate, if you could establish that it is a noteworthy nickname, then it'd probably be appropriate to add.\", shape=(), dtype=string)\n",
            "tf.Tensor([0 0 0 0 0 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor(b\"Yarrr! \\n\\nHeil Hitler, matey!\\n\\nYou're invited to comment on the FAC of the article on Kronan.\\n\\nAnd that goes for anyone else skulking around this talkpage. Go on. Do your worst!\\n\\n A little gift  \\n\\nI stopped by just to say Thank You!  D   talk\", shape=(), dtype=string)\n",
            "tf.Tensor([1 0 0 0 0 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor(b'\"==Please stop vandalizing the Halo 3 article==\\n\\nYou have continually vandalized the Halo 3 page with this \"\"plot\"\" nonsnese, and then replied to it\\'s deletion with a string of hate words and censor bypasses. Please stop.\\n\\n\"', shape=(), dtype=string)\n",
            "tf.Tensor([0 0 0 0 0 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor(b'\"\\nWhile the Isle of Man may have been a well known tax haven in 1998 according to the reference, I wonder if it is still considered one \"\"Today\"\" twelve or more years later? There have been significant changes in the last decade. I think that it is still a low tax regime but \"\"haven\"\"?   \"', shape=(), dtype=string)\n",
            "tf.Tensor([0 0 0 0 0 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor(b'PEOPLE ON THIS SITE SUCK  \\n\\nPEOPLE ON THIS SITE SUCK', shape=(), dtype=string)\n",
            "tf.Tensor([1 0 0 0 1 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor(b'Please stop. If you continue to vandalise the other pages, as you did to Claudette Colbert, you will be blocked.\\n\\nColbert had two husbands. She divorced the first husband immediately. She lost the second husband. Therefore, she was a widow.\\nSpouse(s), Norman Foster (1928-1935), \\nDr. Joel Pressman (1935 \\xe2\\x80\\x93 his death in 1968),\\nShe was interred beside her second husband.\\n \\nBecause it erased a public fact for a personal thought, is not it destruction?', shape=(), dtype=string)\n",
            "tf.Tensor([0 0 0 0 0 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor(b'Someone needs to remove lott 71.227.167.147', shape=(), dtype=string)\n",
            "tf.Tensor([0 0 0 0 0 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor(b\"I submitted this information from the Carina Software Voyager program. Because everyone online seems to think Sothis rises the same day every year at every latitude. The date July 20 is Julian and comes from 30 degree GIza and Memphis. At 31 degree Alexandria (and Ur) the absence is 72 days instead of 70 because it cannot be seen July 20 and it rises a day later on July 21. Septua-Gint means 72 not 70. That's the first fact the rise is pending latitude. The further fact is that rise at Memphis is July 17 not July 20 thru the years 2782-1872bc which means in 2782bc the July 20 rise of Sothis on Thoth 1 is already the 4th rising having been seen July 17 on epagum day 3. Thus Thoth 1 must slip back 12 years 3 leap days to be July 17 the first day of rising. When information like this is submitted and deleted, it is arrogance and wicked heart that does so. So i submit no longer, and advise many never to donate cash to this cause. 98.144.71.174\", shape=(), dtype=string)\n",
            "tf.Tensor([0 0 0 0 0 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor(b'\"\\n\\n Request \\n\\nChimp, can you do me a favor, please? I saw that you produced someone\\'s edit count during their RfA using Interiot\\'s new tool. I can\\'t seem to get this to work, but I\\'d really like to know what my latest count is. If it\\'s not too much trouble, and if you have time, would you mind producing mine for me? (But if it\\'s any trouble, please ignore this request.) Many thanks,  (talk) \"', shape=(), dtype=string)\n",
            "tf.Tensor([0 0 0 0 0 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor(b'Some asshole keeps changing the dates\\n\\nAdvanced Warfighter specifically states that the game took place in 2013 yet some asshole idiot keeps changing it to 2014. Please do something about that.', shape=(), dtype=string)\n",
            "tf.Tensor([1 0 1 0 1 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor(b'nAH!!! MINE SEEMS TO BE  JUST AS ACCCURATE AS THAT DESCRIPTION.IT MIGHT BE GROSSER,BUT STILL ACCURATE.BYBY!!!', shape=(), dtype=string)\n",
            "tf.Tensor([0 0 0 0 0 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor(b'.\\n\\nReaders are invited to review this report on Robert G. Davis rent-a-shills at Wikipedia', shape=(), dtype=string)\n",
            "tf.Tensor([0 0 0 0 0 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor(b\"I was hoping that  and  might have been your edits (they looked medical ). The one about panic and exhaustion, I thought may have been an anecdote, possibly reported somewhere. I'll keep searching for sources.\\nI've copyedited Simon Mitchell a bit and commented at WP:Articles for deletion/Captain Trevor Jackson, calling for a keep on Simon Mitchell. You should comment there when you get a moment to spare. I'll find time later to see if Captain Trevor Jackson has sufficient notability to justify it, but WP:BLP1E may be a problem.\", shape=(), dtype=string)\n",
            "tf.Tensor([0 0 0 0 0 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor(b', 16 December 2010 (UTC)\\n Marseille is not an English form; it does not appear as a headword in the OED while Marseilles does.  This is not a mere personal opinion, as you misleading suggest, because the OED and Economist are excellent reliable sources.   21:56', shape=(), dtype=string)\n",
            "tf.Tensor([0 0 0 0 0 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor(b\"By saying Jubilees is not canonical in any mainstream denomination, you are revealing your abject ignorance and bias POV, because while your personal religion may not consider it canonical, the Ethiopian Orthodox Christians and Ethiopian Jews do, and they are Abrahamic.  The Orthodox Christians make up a majority in Ethiopia.  The Constantinian Christians in the Roman Empire,  and the Pharisee Sanhedrin both tried to do away with Jubilees, but wikipedia is neutral and does not subscribe to any POV in disputes like that, nor will it assist you in attemting to marginalize Ethiopians' religious beliefs.\", shape=(), dtype=string)\n",
            "tf.Tensor([0 0 0 0 0 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor(b'\"\\nHe does appear to be a bit of a fantasist. To be fair, he has carved a nice little career for himself and more fool the mugs that buy his books and believe what he says. But, like many people contributing to this page, I come from that background and whenever his name is mentioned the response is always \"\"Dave who?\"\" No-one had ever heard of him at all until the books started coming out. \"', shape=(), dtype=string)\n",
            "tf.Tensor([0 0 0 0 0 0], shape=(6,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skL7AmVCNYVG",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "Clean out non-alphabetic chars, lowercase, pad beginning of the comment to X length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKvbOXnQ8LJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing pipeline\n",
        "def preprocess(x, y, max_length=200):\n",
        "    x = tf.strings.regex_replace(x, rb\"<br\\s*/?>\", b\" \")\n",
        "    x = tf.strings.regex_replace(x, b\"[^a-zA-Z']\", b\" \")\n",
        "    x = tf.strings.regex_replace(x, b\"([a-zA-Z]+)(')\", r\"\\1\")\n",
        "    x = tf.strings.lower(x)\n",
        "    x = tf.strings.split(x)\n",
        "    x = x.to_tensor(default_value=\"0\")\n",
        "    paddings = tf.constant([[0, 0], [max_length, 0]])\n",
        "    x = tf.pad(x,  paddings, constant_values=b\"<pad>\")\n",
        "    x = tf.RaggedTensor.from_tensor(x, padding=\"0\")\n",
        "    x = x[:, -max_length:]\n",
        "    x = x.to_tensor()\n",
        "    return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KisA375Y9NXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "9e069b09-d77e-4682-9384-f1a1c17d8ae5"
      },
      "source": [
        "for x,y in train_ds.batch(16).take(1).map(preprocess):\n",
        "    print(x, x.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[b'<pad>' b'<pad>' b'<pad>' ... b'appropriate' b'to' b'add']\n",
            " [b'<pad>' b'<pad>' b'<pad>' ... b'you' b'd' b'talk']\n",
            " [b'<pad>' b'<pad>' b'<pad>' ... b'bypasses' b'please' b'stop']\n",
            " ...\n",
            " [b'<pad>' b'<pad>' b'<pad>' ... b'excellent' b'reliable' b'sources']\n",
            " [b'<pad>' b'<pad>' b'<pad>' ... b'ethiopians' b'religious' b'beliefs']\n",
            " [b'<pad>' b'<pad>' b'<pad>' ... b'started' b'coming' b'out']], shape=(16, 200), dtype=string) (16, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTXmXaJN94rD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenizer\n",
        "def make_vocabulary(dataset):\n",
        "    vocabulary = Counter()\n",
        "    for x, _ in dataset.batch(1).map(preprocess):\n",
        "        for review in x:\n",
        "            vocabulary.update(review.numpy().tolist())\n",
        "    return vocabulary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5-QWnXSGvuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vocab size\n",
        "VOCABULARY_SIZE = 10000\n",
        "vocabulary = make_vocabulary(train_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik65jcX1HaTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "bd386845-9208-4f14-f434-c584c0067684"
      },
      "source": [
        "vocabulary.most_common(20)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(b'<pad>', 3671492),\n",
              " (b'the', 65757),\n",
              " (b'to', 40769),\n",
              " (b'and', 29575),\n",
              " (b'of', 29174),\n",
              " (b'a', 28945),\n",
              " (b'you', 27818),\n",
              " (b'i', 27785),\n",
              " (b'is', 23495),\n",
              " (b'that', 20745),\n",
              " (b'in', 19015),\n",
              " (b'it', 18357),\n",
              " (b'for', 14025),\n",
              " (b'this', 13594),\n",
              " (b'not', 12818),\n",
              " (b'on', 12224),\n",
              " (b'be', 11891),\n",
              " (b'as', 10441),\n",
              " (b'have', 9935),\n",
              " (b'are', 9640)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWqxvcY_HoLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Truncated vocabulary (to 10k words)\n",
        "vocab_trunc = tf.constant([i[0] for i in vocabulary.most_common(VOCABULARY_SIZE)])\n",
        "vocab_trunc_ids = tf.range(tf.shape(vocab_trunc)[0], dtype=tf.int64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYMjt-vYOBhy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "ce482337-cf8f-4a53-e790-95849233e19e"
      },
      "source": [
        "# Out of vocabulary buckets\n",
        "n_oov_buckets = VOCABULARY_SIZE // 20\n",
        "vocab_init = tf.lookup.KeyValueTensorInitializer(vocab_trunc, vocab_trunc_ids)\n",
        "table = tf.lookup.StaticVocabularyTable(vocab_init, n_oov_buckets)\n",
        "table.lookup(tf.constant([b\"this is damn a hateful shit comment\".split()]))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=153851, shape=(1, 7), dtype=int64, numpy=array([[  13,    8, 1728,    5, 7616,  433,  187]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5nIvgWkOtm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode words\n",
        "def encode_words(x, y):\n",
        "    return table.lookup(x), y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyHdj2_YNvL-",
        "colab_type": "text"
      },
      "source": [
        "## Train/val dataset creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtFBDlMvUYU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train BS16\n",
        "train_dataset = (\n",
        "    train_ds.batch(16)\n",
        "    .map(preprocess)\n",
        "    .map(encode_words)\n",
        "    .repeat()\n",
        "    .prefetch(-1)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K29d4K7zU7Rr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "a8a6aff9-c847-426b-b662-5f6bd88a4b89"
      },
      "source": [
        "# Check contents\n",
        "for x ,y in train_dataset.take(1):\n",
        "    print(x[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     1   146     8   563\n",
            "    14    45 10192     3     8    14  1360     2    16     9   158    20\n",
            "  1482   877     1   387    51   627     9   241    89    17    99   700\n",
            "   113   228    19   484    10    25 10322    35  6007     3  3750   506\n",
            "    34    53  1772    21     6   104  2733     9    11     8     5  3852\n",
            "  4087    85  3244   301    16   461     2   140], shape=(200,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKypVD3E7j3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Validation BS16\n",
        "val_dataset = (\n",
        "    val_ds.batch(16)\n",
        "    .map(preprocess)\n",
        "    .map(encode_words)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grjp87ji-6DU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Steps\n",
        "train_steps = len(train_df_small) // 16\n",
        "val_steps = len(val_df_small) // 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZekPsSBoQfxW",
        "colab_type": "text"
      },
      "source": [
        "# 3. Models\n",
        "\n",
        "Models used:<br>\n",
        "- M1: LSTM + fixed class weights (embedding64 + 2 bidirectional layers)\n",
        "- M2: M1 + undersampling 0s + oversampling small cats + embedding128\n",
        "- M3: LSTM + focal loss (embedding256, lower dropouts + 2 bidirectional layers)\n",
        "- M4: M1 + pre-trained Glove embeddings (200d), back to BCE loss\n",
        "- M5: Hybrid LSTM+Conv + Glove embeddings (200d + Conv1D*128 + 2 bidirectional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFDAvMI5Sltv",
        "colab_type": "text"
      },
      "source": [
        "## M1: LSTM + fixed class weights \n",
        "64 Embeddings + 2 bi-directional LSTM layers "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqw5MYvyS9NX",
        "colab_type": "text"
      },
      "source": [
        "### Create M1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrIxjhOq_Fjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define model creator\n",
        "def LSTMlearner(\n",
        "    n_categories, embedding_size, lstm_size, lstm_dropout, dropout\n",
        "):\n",
        "    return keras.models.Sequential(\n",
        "        [\n",
        "            keras.layers.Embedding(\n",
        "                VOCABULARY_SIZE + n_oov_buckets,\n",
        "                embedding_size,\n",
        "                mask_zero=True,\n",
        "                input_shape=[None],\n",
        "            ),\n",
        "            keras.layers.Bidirectional(\n",
        "                keras.layers.LSTM(\n",
        "                    lstm_size, dropout=lstm_dropout, return_sequences=True\n",
        "                )\n",
        "            ),\n",
        "            keras.layers.Bidirectional(\n",
        "                keras.layers.LSTM(\n",
        "                    lstm_size, dropout=lstm_dropout, return_sequences=True\n",
        "                )\n",
        "            ),\n",
        "            keras.layers.GlobalMaxPool1D(),\n",
        "            keras.layers.Dropout(dropout),\n",
        "            keras.layers.Dense(n_categories, activation=keras.activations.sigmoid),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksKm5-bB_Sgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create and compile\n",
        "model_1 = LSTMlearner(\n",
        "    n_categories=6,\n",
        "    embedding_size=64,\n",
        "    lstm_size=64,\n",
        "    lstm_dropout=0.2,\n",
        "    dropout=0.5,\n",
        ")\n",
        "\n",
        "model_1.compile(\n",
        "    loss=keras.losses.binary_crossentropy,\n",
        "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
        "    metrics=[\n",
        "        keras.metrics.binary_accuracy,\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5SIQvx7S_Uq",
        "colab_type": "text"
      },
      "source": [
        "### Train M1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0ngJedAAPdH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "01f25914-c55c-46d3-e511-4d0ab41858b2"
      },
      "source": [
        "# Train\n",
        "history = model_1.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=train_steps // 6,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=val_steps // 6,\n",
        "    epochs=6,\n",
        "    class_weight={0: 1., 1: 10.},\n",
        "    callbacks=[\n",
        "        keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.3),\n",
        "        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 265 steps, validate for 33 steps\n",
            "Epoch 1/6\n",
            "265/265 [==============================] - 146s 551ms/step - loss: 0.1697 - binary_accuracy: 0.9625 - val_loss: 0.1450 - val_binary_accuracy: 0.9637\n",
            "Epoch 2/6\n",
            "265/265 [==============================] - 138s 523ms/step - loss: 0.1394 - binary_accuracy: 0.9664 - val_loss: 0.1373 - val_binary_accuracy: 0.9637\n",
            "Epoch 3/6\n",
            "265/265 [==============================] - 139s 524ms/step - loss: 0.1265 - binary_accuracy: 0.9664 - val_loss: 0.1180 - val_binary_accuracy: 0.9637\n",
            "Epoch 4/6\n",
            "265/265 [==============================] - 138s 520ms/step - loss: 0.1090 - binary_accuracy: 0.9663 - val_loss: 0.1067 - val_binary_accuracy: 0.9678\n",
            "Epoch 5/6\n",
            "265/265 [==============================] - 138s 522ms/step - loss: 0.0905 - binary_accuracy: 0.9700 - val_loss: 0.0785 - val_binary_accuracy: 0.9751\n",
            "Epoch 6/6\n",
            "265/265 [==============================] - 139s 523ms/step - loss: 0.0771 - binary_accuracy: 0.9743 - val_loss: 0.0692 - val_binary_accuracy: 0.9760\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Ec_eDpTBFM",
        "colab_type": "text"
      },
      "source": [
        "### Predict M1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPFlShaa-0E1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model_1.predict_generator(val_dataset, steps=val_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T008TARCKQSF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "89946434-c509-4a37-a2d7-97873ce7a8da"
      },
      "source": [
        "print(\n",
        "    \"Label distribution in validation set:\\n\\n\",\n",
        "    val_df_small.iloc[:,2:].apply(np.mean),\n",
        "    \"\\n\\nClassification report of M1:\\n\\n\",\n",
        "    sk.metrics.classification_report(val_df_small.iloc[:len(preds), 2:], np.round(preds))\n",
        ")"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label distribution in validation set:\n",
            "\n",
            " toxic            0.106550\n",
            "severe_toxic     0.012222\n",
            "obscene          0.060796\n",
            "threat           0.005014\n",
            "insult           0.057976\n",
            "identity_hate    0.010655\n",
            "dtype: float64 \n",
            "\n",
            "Classification report of M1:\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.73      0.70       310\n",
            "           1       0.62      0.41      0.49        58\n",
            "           2       0.64      0.74      0.69       169\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.66      0.73      0.69       167\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.62      0.71      0.66       704\n",
            "   macro avg       0.43      0.44      0.43       704\n",
            "weighted avg       0.66      0.71      0.68       704\n",
            " samples avg       0.06      0.06      0.06       704\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78-dn-O6TECp",
        "colab_type": "text"
      },
      "source": [
        "## M2: undersample all-0s + oversample small categories \n",
        "\n",
        "Let's also reduce dropout and class weights, as the model is having a hard time learning, not even close to overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffEGQV3OLePw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "433f5a85-e757-409e-d099-01b5f46b427d"
      },
      "source": [
        "# Check how many all-0-label cases we have\n",
        "print(f\"Total length of full train dataset: {train_df.shape[0]}\")\n",
        "train_df_small_no_0 = train_df[train_df.iloc[:,2:].apply(np.mean, axis=1) > 0]\n",
        "print(f\"Total length if all-0-label examples are removed: {train_df_small_no_0.shape[0]}\")"
      ],
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total length of full train dataset: 127657\n",
            "Total length if all-0-label examples are removed: 13009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvKiNTFITn-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create sampling weights for the smallest label categories \n",
        "weights = (\n",
        "    train_df[\"severe_toxic\"] * 4 + \\\n",
        "    train_df[\"threat\"] * 4 + \\\n",
        "    train_df[\"identity_hate\"] * 4 \\\n",
        "    )\n",
        "\n",
        "# Sample 20% of the entire train dataframe with these weights\n",
        "train_append = train_df.sample(frac=0.2, weights=weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcZATLNXSEhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "b208cbb2-6df2-4a71-b60b-2a50cd06d04e"
      },
      "source": [
        "# Compare label distributions (top - new, bottom - old)\n",
        "print(\n",
        "    train_append.iloc[:, 2:].describe().loc[\"mean\"],\n",
        "    train_df.iloc[:, 2:].describe().loc[\"mean\"]\n",
        ")"
      ],
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic            0.135247\n",
            "severe_toxic     0.035565\n",
            "obscene          0.087188\n",
            "threat           0.010928\n",
            "insult           0.083624\n",
            "identity_hate    0.029807\n",
            "Name: mean, dtype: float64 toxic            0.095913\n",
            "severe_toxic     0.009862\n",
            "obscene          0.052813\n",
            "threat           0.002969\n",
            "insult           0.049233\n",
            "identity_hate    0.008703\n",
            "Name: mean, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWW-vqnOL81f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Append and shuffle train dataset\n",
        "train_df_small_no_0 = train_df_small_no_0.append(train_append, ignore_index=True)\n",
        "train_ds_undersampled = df_to_ds(train_df_small_no_0.sample(frac=1))\n",
        "\n",
        "train_dataset = (\n",
        "    train_ds_undersampled.batch(16)\n",
        "    .map(preprocess)\n",
        "    .map(encode_words)\n",
        "    .repeat()\n",
        "    .prefetch(-1)\n",
        ")\n",
        "\n",
        "train_steps = train_df_small_no_0.shape[0] // 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdrgn2u_T3eB",
        "colab_type": "text"
      },
      "source": [
        "## Create M2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKCuVS8ybJNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2 = LSTMlearner(\n",
        "    n_categories=6,\n",
        "    embedding_size=128,\n",
        "    lstm_size=64,\n",
        "    lstm_dropout=0.2,\n",
        "    dropout=0.3,\n",
        ")\n",
        "\n",
        "model_2.compile(\n",
        "    loss=keras.losses.binary_crossentropy,\n",
        "    optimizer=keras.optimizers.Adam(lr=5e-4),\n",
        "    metrics=[\n",
        "        keras.metrics.binary_accuracy,\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TzBFtVkT7rQ",
        "colab_type": "text"
      },
      "source": [
        "## Train M2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1ZABGvOMEjp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "ed9fcc6b-dbcd-4a4b-e1f7-6456f71932d0"
      },
      "source": [
        "history = model_2.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=train_steps // 6,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=val_steps // 6,\n",
        "    epochs=6,\n",
        "    class_weight={0: 1., 1: 2.5},\n",
        "    callbacks=[\n",
        "        keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.3),\n",
        "        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 401 steps, validate for 33 steps\n",
            "Epoch 1/6\n",
            "401/401 [==============================] - 251s 626ms/step - loss: 0.3349 - binary_accuracy: 0.8664 - val_loss: 0.1000 - val_binary_accuracy: 0.9722\n",
            "Epoch 2/6\n",
            "401/401 [==============================] - 233s 581ms/step - loss: 0.2093 - binary_accuracy: 0.9174 - val_loss: 0.0695 - val_binary_accuracy: 0.9789\n",
            "Epoch 3/6\n",
            "401/401 [==============================] - 232s 579ms/step - loss: 0.1942 - binary_accuracy: 0.9241 - val_loss: 0.0666 - val_binary_accuracy: 0.9779\n",
            "Epoch 4/6\n",
            "401/401 [==============================] - 232s 579ms/step - loss: 0.1885 - binary_accuracy: 0.9257 - val_loss: 0.0669 - val_binary_accuracy: 0.9811\n",
            "Epoch 5/6\n",
            "401/401 [==============================] - 231s 576ms/step - loss: 0.1757 - binary_accuracy: 0.9313 - val_loss: 0.0616 - val_binary_accuracy: 0.9807\n",
            "Epoch 6/6\n",
            "401/401 [==============================] - 231s 576ms/step - loss: 0.1732 - binary_accuracy: 0.9306 - val_loss: 0.0561 - val_binary_accuracy: 0.9833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_8O6V9IT9y0",
        "colab_type": "text"
      },
      "source": [
        "## Predict M2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ5ecqupfp5H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "ed23a56b-e281-4d5a-b451-2f96d0509d84"
      },
      "source": [
        "preds = model_2.predict_generator(val_dataset, steps=val_steps)\n",
        "print(\n",
        "    \"\\n\\nClassification report of M1:\\n\\n\",\n",
        "    sk.metrics.classification_report(val_df_small.iloc[:len(preds), 2:], np.round(preds))\n",
        ")"
      ],
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Classification report of M1:\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.86      0.77       339\n",
            "           1       0.68      0.44      0.53        39\n",
            "           2       0.79      0.80      0.79       194\n",
            "           3       0.00      0.00      0.00        16\n",
            "           4       0.77      0.73      0.75       185\n",
            "           5       0.00      0.00      0.00        34\n",
            "\n",
            "   micro avg       0.74      0.74      0.74       807\n",
            "   macro avg       0.49      0.47      0.47       807\n",
            "weighted avg       0.69      0.74      0.71       807\n",
            " samples avg       0.08      0.08      0.08       807\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gss9X7TUFXB",
        "colab_type": "text"
      },
      "source": [
        "# M3: Focal loss, embedding256, lower dropouts\n",
        "\n",
        "Focal loss was originally created for object detection in images problems, where you have a lot of empty background pixels and very few pixels that contain the actual object (i.e. class imbalance). The loss puts more emphasis on \"difficult\" or misclassified examples and downscales easy examples, intensity of which is regulated with gamma and alpha parameters.<br><br>More info: [Original paper](https://arxiv.org/abs/1708.02002), [Medium summary](https://towardsdatascience.com/review-retinanet-focal-loss-object-detection-38fba6afabe4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnlqLyYvNTJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Original implementation by (slightly adjusted here) and props for Umberto Griffo \n",
        "# Source: https://github.com/umbertogriffo/focal-loss-keras/blob/master/losses.py\n",
        "import keras.backend as K\n",
        "\n",
        "k_eps = K.epsilon()\n",
        "\n",
        "def binary_focal_loss(gamma=2., alpha=.25):\n",
        "    def binary_focal_loss_fixed(y_true, y_pred):\n",
        "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "        epsilon = k_eps\n",
        "        # clip to prevent NaN's and Inf's\n",
        "        pt_1 = tf.clip_by_value(pt_1, epsilon, 1. - epsilon)\n",
        "        pt_0 = tf.clip_by_value(pt_0, epsilon, 1. - epsilon)\n",
        "        return -tf.reduce_sum(alpha * tf.math.pow(1. - pt_1, gamma) * tf.math.log(pt_1)) \\\n",
        "               -tf.reduce_sum((1 - alpha) * tf.math.pow(pt_0, gamma) * tf.math.log(1. - pt_0))\n",
        "    return binary_focal_loss_fixed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHQOGg_8VocI",
        "colab_type": "text"
      },
      "source": [
        "### Create M3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTh0Jst5dqKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_3 = LSTMlearner(\n",
        "    n_categories=6,\n",
        "    embedding_size=256,\n",
        "    lstm_size=64,\n",
        "    lstm_dropout=0.15,\n",
        "    dropout=0.3,\n",
        ")\n",
        "\n",
        "model_3.compile(\n",
        "    loss=binary_focal_loss(),\n",
        "    optimizer=keras.optimizers.Adam(lr=5e-4),\n",
        "    metrics=[\n",
        "        keras.metrics.binary_accuracy,\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOlwiY63Vtr0",
        "colab_type": "text"
      },
      "source": [
        "### Train M3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bMaPV7wlzYK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "1e2e5c37-89d4-4ac8-abde-0ae3d3446a46"
      },
      "source": [
        "history = model_3.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=train_steps // 6,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=val_steps // 6,\n",
        "    epochs=6,\n",
        "    # class_weight={0: 1., 1: 2.5},\n",
        "    callbacks=[\n",
        "        keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.3),\n",
        "        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 393,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 401 steps, validate for 33 steps\n",
            "Epoch 1/6\n",
            "401/401 [==============================] - 301s 749ms/step - loss: 3.4138 - binary_accuracy: 0.8620 - val_loss: 0.9128 - val_binary_accuracy: 0.9729\n",
            "Epoch 2/6\n",
            "401/401 [==============================] - 275s 686ms/step - loss: 2.0088 - binary_accuracy: 0.9123 - val_loss: 0.6590 - val_binary_accuracy: 0.9779\n",
            "Epoch 3/6\n",
            "401/401 [==============================] - 274s 682ms/step - loss: 1.9066 - binary_accuracy: 0.9143 - val_loss: 0.5899 - val_binary_accuracy: 0.9814\n",
            "Epoch 4/6\n",
            "401/401 [==============================] - 275s 687ms/step - loss: 1.8589 - binary_accuracy: 0.9155 - val_loss: 0.5798 - val_binary_accuracy: 0.9817\n",
            "Epoch 5/6\n",
            "401/401 [==============================] - 277s 691ms/step - loss: 1.7154 - binary_accuracy: 0.9221 - val_loss: 0.6003 - val_binary_accuracy: 0.9830\n",
            "Epoch 6/6\n",
            "401/401 [==============================] - 276s 687ms/step - loss: 1.6603 - binary_accuracy: 0.9223 - val_loss: 0.5301 - val_binary_accuracy: 0.9839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb9MNgGcVv8X",
        "colab_type": "text"
      },
      "source": [
        "### Predict M3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqtsAaf03Lc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "c23ce07c-651c-409e-97c5-4fe780bcefe1"
      },
      "source": [
        "preds = model_3.predict_generator(val_dataset, steps=val_steps)\n",
        "print(\n",
        "    \"\\n\\nClassification report of M1:\\n\\n\",\n",
        "    sk.metrics.classification_report(val_df_small.iloc[:len(preds), 2:], np.round(preds))\n",
        ")"
      ],
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Classification report of M1:\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.78      0.81       339\n",
            "           1       0.00      0.00      0.00        39\n",
            "           2       0.91      0.62      0.74       194\n",
            "           3       0.00      0.00      0.00        16\n",
            "           4       0.91      0.39      0.55       185\n",
            "           5       0.00      0.00      0.00        34\n",
            "\n",
            "   micro avg       0.88      0.57      0.69       807\n",
            "   macro avg       0.45      0.30      0.35       807\n",
            "weighted avg       0.79      0.57      0.65       807\n",
            " samples avg       0.08      0.06      0.07       807\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfx-MB8qVyGx",
        "colab_type": "text"
      },
      "source": [
        "## M4: Pre-trained Glove embeddings\n",
        "\n",
        "200-dimensional embeddings version of Glove is used. The embedding layer is first trained frozen, then some more epochs with the layer unfrozen and longer comments (200 words -> 300)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4Pbsdtnuvol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read embeddings into a dict\n",
        "embeddings_index = {}\n",
        "with open(os.path.join(DATA_DIR, 'glove.6B.200d.txt')) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "# Create embedding array based on our vocab\n",
        "embedding_matrix = np.zeros((VOCABULARY_SIZE + n_oov_buckets, 200))\n",
        "for word, i in zip(vocab_trunc, vocab_trunc_ids):\n",
        "    embedding_vector = embeddings_index.get(word.numpy())\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i.numpy()] = embedding_vector\n",
        "\n",
        "# Pre-create embedding layer\n",
        "embedding_layer = keras.layers.Embedding(VOCABULARY_SIZE + n_oov_buckets,\n",
        "                                        200,\n",
        "                                        mask_zero=True,\n",
        "                                        embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                                        trainable=False,\n",
        "                                        input_shape=[None])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xoZOp0xWMWc",
        "colab_type": "text"
      },
      "source": [
        "### Create M4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QC2c4WU42hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LSTM_transfer_learner(\n",
        "    n_categories, lstm_size, lstm_dropout, dropout\n",
        "):\n",
        "    return keras.models.Sequential(\n",
        "        [\n",
        "            embedding_layer,\n",
        "            keras.layers.Bidirectional(\n",
        "                keras.layers.LSTM(\n",
        "                    lstm_size, dropout=lstm_dropout, return_sequences=True\n",
        "                )\n",
        "            ),\n",
        "            keras.layers.Bidirectional(\n",
        "                keras.layers.LSTM(\n",
        "                    lstm_size, dropout=lstm_dropout, return_sequences=True\n",
        "                )\n",
        "            ),\n",
        "            keras.layers.GlobalMaxPool1D(),\n",
        "            keras.layers.Dropout(dropout),\n",
        "            keras.layers.Dense(n_categories, activation=keras.activations.sigmoid),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DzxUaLB5-34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_4 = LSTM_transfer_learner(\n",
        "    n_categories=6,\n",
        "    lstm_size=64,\n",
        "    lstm_dropout=0.15,\n",
        "    dropout=0.3,\n",
        ")\n",
        "\n",
        "model_4.compile(\n",
        "    loss=keras.losses.binary_crossentropy,\n",
        "    optimizer=keras.optimizers.Adam(lr=5e-4),\n",
        "    metrics=[\n",
        "        keras.metrics.binary_accuracy,\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHYa5hmK6G1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "ea244aef-261e-4776-f0bf-850ad903a265"
      },
      "source": [
        "model_4.summary()"
      ],
      "execution_count": 441,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_20 (Embedding)     (None, None, 200)         2100000   \n",
            "_________________________________________________________________\n",
            "bidirectional_46 (Bidirectio (None, None, 128)         135680    \n",
            "_________________________________________________________________\n",
            "bidirectional_47 (Bidirectio (None, None, 128)         98816     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_23 (Glo (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 2,335,270\n",
            "Trainable params: 2,335,270\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzpNT_u_WRTe",
        "colab_type": "text"
      },
      "source": [
        "### Train M4 (frozen)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTLE2wD_6KGz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "b45893aa-71b9-4568-ae93-5d5de4e8a10c"
      },
      "source": [
        "history = model_4.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=train_steps // 6,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=val_steps // 6,\n",
        "    epochs=6,\n",
        "    callbacks=[\n",
        "        keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.3),\n",
        "        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 442,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 401 steps, validate for 33 steps\n",
            "Epoch 1/6\n",
            "401/401 [==============================] - 288s 718ms/step - loss: 0.3138 - binary_accuracy: 0.8784 - val_loss: 0.0859 - val_binary_accuracy: 0.9732\n",
            "Epoch 2/6\n",
            "401/401 [==============================] - 254s 633ms/step - loss: 0.1949 - binary_accuracy: 0.9241 - val_loss: 0.0654 - val_binary_accuracy: 0.9785\n",
            "Epoch 3/6\n",
            "401/401 [==============================] - 255s 636ms/step - loss: 0.1909 - binary_accuracy: 0.9252 - val_loss: 0.0598 - val_binary_accuracy: 0.9814\n",
            "Epoch 4/6\n",
            "401/401 [==============================] - 255s 636ms/step - loss: 0.1882 - binary_accuracy: 0.9258 - val_loss: 0.0616 - val_binary_accuracy: 0.9814\n",
            "Epoch 5/6\n",
            "401/401 [==============================] - 263s 655ms/step - loss: 0.1722 - binary_accuracy: 0.9312 - val_loss: 0.0584 - val_binary_accuracy: 0.9823\n",
            "Epoch 6/6\n",
            "401/401 [==============================] - 253s 630ms/step - loss: 0.1694 - binary_accuracy: 0.9318 - val_loss: 0.0574 - val_binary_accuracy: 0.9823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvfwx0g06d34",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "53618a20-9e77-4edc-a482-cfeb48e7015b"
      },
      "source": [
        "model_4._layers[:3]"
      ],
      "execution_count": 443,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7fb99d39f240>,\n",
              " <tensorflow.python.keras.layers.embeddings.Embedding at 0x7fb91b269550>,\n",
              " <tensorflow.python.keras.layers.wrappers.Bidirectional at 0x7fb99d3c8470>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 443
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Jszp8FPWT4t",
        "colab_type": "text"
      },
      "source": [
        "### Train M4 (unfrozen + longer comments)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B5-S3rS_MN9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a47f9905-1f92-4bc8-bf94-deaec070588f"
      },
      "source": [
        "model_4._layers[1].trainable = True\n",
        "model_4._layers[1].trainable "
      ],
      "execution_count": 444,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 444
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MvpaQjjB-uQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = (\n",
        "    train_ds_undersampled.batch(16)\n",
        "    .map(partial(preprocess, max_length=300))\n",
        "    .map(encode_words)\n",
        "    .repeat()\n",
        "    .prefetch(-1)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsJM9-ZR_QZF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "outputId": "a61c7297-34d0-4e8a-dca1-7c599a54b952"
      },
      "source": [
        "history = model_4.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=train_steps // 6,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=val_steps // 6,\n",
        "    epochs=6,\n",
        "    class_weight={'0': 1., '1': 2.5},\n",
        "    callbacks=[\n",
        "        keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.3),\n",
        "        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 446,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 401 steps, validate for 33 steps\n",
            "Epoch 1/6\n",
            "401/401 [==============================] - 375s 936ms/step - loss: 0.1641 - binary_accuracy: 0.9338 - val_loss: 0.0535 - val_binary_accuracy: 0.9814\n",
            "Epoch 2/6\n",
            "401/401 [==============================] - 376s 937ms/step - loss: 0.1517 - binary_accuracy: 0.9392 - val_loss: 0.0527 - val_binary_accuracy: 0.9820\n",
            "Epoch 3/6\n",
            "401/401 [==============================] - 375s 935ms/step - loss: 0.1583 - binary_accuracy: 0.9366 - val_loss: 0.0538 - val_binary_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "401/401 [==============================] - 385s 960ms/step - loss: 0.1580 - binary_accuracy: 0.9372 - val_loss: 0.0569 - val_binary_accuracy: 0.9807\n",
            "Epoch 5/6\n",
            "144/401 [=========>....................] - ETA: 3:55 - loss: 0.1635 - binary_accuracy: 0.9347WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy,lr\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-446-8ddfc769f966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     callbacks=[\n\u001b[1;32m      9\u001b[0m         \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     ],\n\u001b[1;32m     12\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWiCXuFXWn5S",
        "colab_type": "text"
      },
      "source": [
        "### Predict M4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-4M-WN1J3LO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "4d83d13d-52ee-443c-ef8b-99a643472bc0"
      },
      "source": [
        "val_dataset = (\n",
        "    val_ds.batch(16)\n",
        "    .map(partial(preprocess, max_length=300))\n",
        "    .map(encode_words)\n",
        ")\n",
        "\n",
        "preds = model_4.predict_generator(val_dataset, steps=val_steps)\n",
        "print(\n",
        "    \"\\n\\nClassification report of M1:\\n\\n\",\n",
        "    sk.metrics.classification_report(val_df_small.iloc[:len(preds), 2:], np.round(preds))\n",
        ")"
      ],
      "execution_count": 447,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Classification report of M1:\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.90      0.73       339\n",
            "           1       0.72      0.46      0.56        39\n",
            "           2       0.80      0.80      0.80       194\n",
            "           3       0.00      0.00      0.00        16\n",
            "           4       0.78      0.72      0.75       185\n",
            "           5       0.00      0.00      0.00        34\n",
            "\n",
            "   micro avg       0.69      0.76      0.72       807\n",
            "   macro avg       0.49      0.48      0.47       807\n",
            "weighted avg       0.66      0.76      0.70       807\n",
            " samples avg       0.09      0.08      0.08       807\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5o105QpWz1K",
        "colab_type": "text"
      },
      "source": [
        "## M5: Hybrid Conv1D+LSTM model with Glove embeddings\n",
        "\n",
        "Last model, extra conv layer in front -> train with embeddings frozen -> unfreeze and train more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqkRL4IXXDK9",
        "colab_type": "text"
      },
      "source": [
        "### Create M5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hw0F3lO_fDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Hybrid_transfer_learner(\n",
        "    n_categories, conv_size, lstm_size, lstm_dropout, dropout\n",
        "):\n",
        "    return keras.models.Sequential(\n",
        "        [\n",
        "            # Embedding\n",
        "            keras.layers.Embedding(VOCABULARY_SIZE + n_oov_buckets,\n",
        "                200,\n",
        "                mask_zero=True,\n",
        "                embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                trainable=False,\n",
        "                input_shape=[None]),\n",
        "            # Conv layer\n",
        "            keras.layers.Conv1D(\n",
        "                filters=conv_size,\n",
        "                kernel_size=4,\n",
        "                padding=\"same\",\n",
        "                activation=keras.activations.relu,\n",
        "                kernel_initializer=keras.initializers.he_uniform(),\n",
        "            ),\n",
        "            # Dropout 1\n",
        "            keras.layers.Dropout(dropout),\n",
        "            # LSTM 1\n",
        "            keras.layers.Bidirectional(\n",
        "                keras.layers.LSTM(\n",
        "                    lstm_size, dropout=lstm_dropout, return_sequences=True\n",
        "                )\n",
        "            ),\n",
        "            # LSTM 2\n",
        "            keras.layers.Bidirectional(\n",
        "                keras.layers.LSTM(\n",
        "                    lstm_size, dropout=lstm_dropout, return_sequences=True\n",
        "                )\n",
        "            ),\n",
        "            keras.layers.GlobalMaxPool1D(),\n",
        "            # Dropout 2\n",
        "            keras.layers.Dropout(dropout),\n",
        "            # Output\n",
        "            keras.layers.Dense(n_categories, activation=keras.activations.sigmoid),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrpU7EFnAsz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_5 = Hybrid_transfer_learner(\n",
        "    n_categories=6,\n",
        "    conv_size=128,\n",
        "    lstm_size=64,\n",
        "    lstm_dropout=0.15,\n",
        "    dropout=0.3,\n",
        ")\n",
        "\n",
        "model_5.compile(\n",
        "    loss=keras.losses.binary_crossentropy,\n",
        "    optimizer=keras.optimizers.Adam(lr=5e-4),\n",
        "    metrics=[\n",
        "        keras.metrics.binary_accuracy,\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOXaQyXYXGpp",
        "colab_type": "text"
      },
      "source": [
        "### Train M5 (frozen)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxWaQmoMQGxh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "c9160c87-a1a3-4ad9-ce51-5af3c1552106"
      },
      "source": [
        "history = model_5.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=train_steps // 6,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=val_steps // 6,\n",
        "    epochs=6,\n",
        "    class_weight={'0': 1., '1': 2.5},\n",
        "    callbacks=[\n",
        "        keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.3),\n",
        "        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 457,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 401 steps, validate for 33 steps\n",
            "Epoch 1/6\n",
            "401/401 [==============================] - 330s 824ms/step - loss: 0.4012 - binary_accuracy: 0.8303 - val_loss: 0.2323 - val_binary_accuracy: 0.9637\n",
            "Epoch 2/6\n",
            "401/401 [==============================] - 321s 800ms/step - loss: 0.3758 - binary_accuracy: 0.8381 - val_loss: 0.2117 - val_binary_accuracy: 0.9637\n",
            "Epoch 3/6\n",
            "401/401 [==============================] - 319s 796ms/step - loss: 0.3805 - binary_accuracy: 0.8329 - val_loss: 0.2425 - val_binary_accuracy: 0.9637\n",
            "Epoch 4/6\n",
            "401/401 [==============================] - 319s 796ms/step - loss: 0.3806 - binary_accuracy: 0.8336 - val_loss: 0.2433 - val_binary_accuracy: 0.9637\n",
            "Epoch 5/6\n",
            "401/401 [==============================] - 320s 799ms/step - loss: 0.3696 - binary_accuracy: 0.8399 - val_loss: 0.2355 - val_binary_accuracy: 0.9637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO8JbtzOXYCf",
        "colab_type": "text"
      },
      "source": [
        "### Train M5 (unfrozen, no sampling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7pT7u29RcsW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "094bde1f-e2b7-4b37-d696-3d3504c2c9ae"
      },
      "source": [
        "model_5._layers[1].trainable = True\n",
        "\n",
        "train_dataset = (\n",
        "    train_ds.batch(16)\n",
        "    .map(partial(preprocess, max_length=300))\n",
        "    .map(encode_words)\n",
        "    .repeat()\n",
        "    .prefetch(-1)\n",
        ")\n",
        "\n",
        "train_steps = train_df_small.shape[0] // 16\n",
        "\n",
        "history = model_5.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=train_steps // 6,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=val_steps // 6,\n",
        "    epochs=3,\n",
        "    class_weight={'0': 1., '1': 2.5},\n",
        "    callbacks=[\n",
        "        keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.3),\n",
        "        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 461,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 265 steps, validate for 33 steps\n",
            "Epoch 1/3\n",
            "265/265 [==============================] - 242s 915ms/step - loss: 0.2262 - binary_accuracy: 0.9592 - val_loss: 0.2270 - val_binary_accuracy: 0.9637\n",
            "Epoch 2/3\n",
            "265/265 [==============================] - 224s 845ms/step - loss: 0.2177 - binary_accuracy: 0.9648 - val_loss: 0.2222 - val_binary_accuracy: 0.9637\n",
            "Epoch 3/3\n",
            "265/265 [==============================] - 215s 812ms/step - loss: 0.2129 - binary_accuracy: 0.9651 - val_loss: 0.2179 - val_binary_accuracy: 0.9637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utgrq-oCnlGo",
        "colab_type": "text"
      },
      "source": [
        "# 4. Summary\n",
        "\n",
        "Evaluations on val dataset (Macro F1):<br>\n",
        "- M1: 0.43\n",
        "- M2: 0.47\n",
        "- M3: 0.35\n",
        "- M4: 0.47\n",
        "- M5: "
      ]
    }
  ]
}